{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4903747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#### ENSURE REPRODUCIBLE RESULTS ####\n",
    "\n",
    "# Disable GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Define a single variable that contains a static random seed and use it across your pipeline:\n",
    "seed_value=1\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1f03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PYTHON IMPORTS ####\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import statsmodels.api as sm\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import auc, roc_curve, log_loss\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Activation,MaxPooling2D,Dense,Flatten,Dropout\n",
    "import keras\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe635f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gtFr = pd.read_csv('data/gt.csv')\n",
    "\n",
    "trainIdx, testIdx = train_test_split(gtFr, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03fa563",
   "metadata": {},
   "source": [
    "# Plot some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d262a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dog photos from the dogs vs cats dataset\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# define location of dataset\n",
    "folder = 'images/archive/brain_tumor_dataset/no'\n",
    "\n",
    "# plot first few images\n",
    " for f in os.listdir(filePath)[]:\n",
    "        \n",
    "     # define subplot\n",
    "     pyplot.subplot(330 + 1 + i)\n",
    "        \n",
    "     # define filename\n",
    "     filename = folder + 'no.' + f + '.jpg'\n",
    "        \n",
    "     # load image pixels\n",
    "     image = imread(filename)\n",
    "        \n",
    "     # plot raw pixel data\n",
    "     pyplot.imshow(image)\n",
    "        \n",
    "    # show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc1522",
   "metadata": {},
   "source": [
    "# Read images into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093295db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "filepath_no = 'images/archive/brain_tumor_dataset/no'\n",
    "filepath_yes = 'images/archive/brain_tumor_dataset/yes'\n",
    "\n",
    "photos, labels = list(), list()\n",
    "\n",
    "for filePath, GT in zip([filepath_no,filepath_yes],[0,1]):\n",
    "    \n",
    "    for f in os.listdir(filePath):\n",
    "\n",
    "        # load image\n",
    "        photo = load_img(filepath_no + f, target_size=(200, 200))\n",
    "\n",
    "        # convert to np array\n",
    "        photo = img_to_array(photo)\n",
    "\n",
    "        photos = asarray(photos)\n",
    "        \n",
    "        # store\n",
    "        photos.append(photo)\n",
    "        labels.append(GT)\n",
    "\n",
    "        save('yes_vs_no_brainmri_photos.npy', photos)\n",
    "        save('yes_vs_no_brainmri_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "photos, labels = list(), list()\n",
    "# enumerate files in the directory\n",
    "for file in listdir(folder):\n",
    " # determine class\n",
    " output = 0.0\n",
    " if file.startswith('dog'):\n",
    " output = 1.0\n",
    " # load image\n",
    " \n",
    " # store\n",
    " photos.append(photo)\n",
    " labels.append(output)\n",
    "# convert to a numpy arrays\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "# save the reshaped photos\n",
    "save('dogs_vs_cats_photos.npy', photos)\n",
    "save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a249f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b6992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d24f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(path):\n",
    "    for p in os.listdir(path):\n",
    "        category = p.split(\".\")[0]\n",
    "        category = convert(category)\n",
    "        img_array = imread(os.path.join(path,p),IMREAD_GRAYSCALE)\n",
    "        new_img_array = resize(img_array, dsize=(80, 80))\n",
    "        X.append(new_img_array)\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "filepath_no = 'images/archive/brain_tumor_dataset/no'\n",
    "\n",
    "\n",
    "    category = p.split(\".\")[0]\n",
    "        \n",
    "#cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function create_test_data which takes all training images into a loop\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "convert = lambda category : int(category == 0)\n",
    "\n",
    "# Converts into image array\n",
    "\n",
    "# Resize image into 80 X 80\n",
    "\n",
    "# Append image into X array\n",
    "\n",
    "# Append category value into y array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b6b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data and label\n",
    "X = np.array([np.array(i[0]) for i in training_data]).reshape(-1, len(variable_orders), 25+1, 1) # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i[1] for i in training_data]) # ground truth\n",
    "\n",
    "pID_arr = np.array([i[2] for i in training_data]) # pID array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull_train = dict()\n",
    "yfull_test = []\n",
    "\n",
    "# 6-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=False, random_state=random_state)\n",
    "\n",
    "# Build series of models\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "models = []\n",
    "\n",
    "# Train models\n",
    "results_full = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    print \"Running Fold\", num_fold+1, \"/\", n_folds\n",
    "\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3),input_shape=(np.shape(X)[1],np.shape(X)[2],1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(64,(2,2),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128,(2,2),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128,(2,2),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    optimizer = keras.optimizers.rmsprop(lr=LR, decay=1e-6)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                   loss ='binary_crossentropy',\n",
    "                   metrics =['accuracy'])\n",
    "\n",
    "    num_fold += 1\n",
    "\n",
    "    # Separate data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    pID_train, pID_test = pID_arr[train_index], pID_arr[test_index]\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train, epochs=nb_epoch, verbose=0, validation_data=(X_test, y_test), shuffle=True)\n",
    "\n",
    "    #print model.summary()\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    #Save history\n",
    "    with open('results'+'.txt', 'wb') as file_pi:  \n",
    "        pickle.dump(model.history, file_pi)\n",
    "\n",
    "    # Make predictions\n",
    "    result = model.predict(X_test, verbose=2)\n",
    "\n",
    "    yfull_test.append(result)\n",
    "\n",
    "    # Store predictions\n",
    "    for i in range(len(test_index)):\n",
    "        yfull_train[test_index[i]] = result[i]\n",
    "\n",
    "    resultsFr = pd.DataFrame()\n",
    "    resultsFr['pID'] = pID_test\n",
    "    resultsFr['gt'] = y_test\n",
    "    resultsFr['nqloc'] = result\n",
    "    resultsFr['task'] = 1\n",
    "\n",
    "    results_full = results_full.append(resultsFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ffa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
