{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d65b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#### ENSURE REPRODUCIBLE RESULTS ####\n",
    "\n",
    "# Disable GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Define a single variable that contains a static random seed and use it across your pipeline:\n",
    "seed_value=1\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa4bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PYTHON IMPORTS ####\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import statsmodels.api as sm\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import auc, roc_curve, log_loss\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Activation,MaxPooling2D,Dense,Flatten,Dropout\n",
    "import keras\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2924d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gtFr = pd.read_csv('data/gt.csv')\n",
    "\n",
    "trainIdx, testIdx = train_test_split(gtFr, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f2cbd",
   "metadata": {},
   "source": [
    "# Read images into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ceb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(path):\n",
    "    for p in os.listdir(path):\n",
    "        category = p.split(\".\")[0]\n",
    "        category = convert(category)\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "        X.append(new_img_array)\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438d350e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named cv2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-870fa6bf4a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilepath_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'images/archive/brain_tumor_dataset/no'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cv2"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "filepath_no = 'images/archive/brain_tumor_dataset/no'\n",
    "\n",
    "for p in os.listdir(path):\n",
    "    category = p.split(\".\")[0]\n",
    "        \n",
    "#cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c093fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function create_test_data which takes all training images into a loop\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "convert = lambda category : int(category == 0)\n",
    "\n",
    "# Converts into image array\n",
    "\n",
    "# Resize image into 80 X 80\n",
    "\n",
    "# Append image into X array\n",
    "\n",
    "# Append category value into y array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c237a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data and label\n",
    "X = np.array([np.array(i[0]) for i in training_data]).reshape(-1, len(variable_orders), 25+1, 1) # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae25dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i[1] for i in training_data]) # ground truth\n",
    "\n",
    "pID_arr = np.array([i[2] for i in training_data]) # pID array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc51661",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull_train = dict()\n",
    "yfull_test = []\n",
    "\n",
    "# 6-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=False, random_state=random_state)\n",
    "\n",
    "# Build series of models\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "models = []\n",
    "\n",
    "# Train models\n",
    "results_full = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    print \"Running Fold\", num_fold+1, \"/\", n_folds\n",
    "\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3),input_shape=(np.shape(X)[1],np.shape(X)[2],1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(64,(2,2),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128,(2,2),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128,(2,2),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),padding=\"same\")) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\",padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    optimizer = keras.optimizers.rmsprop(lr=LR, decay=1e-6)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                   loss ='binary_crossentropy',\n",
    "                   metrics =['accuracy'])\n",
    "\n",
    "    num_fold += 1\n",
    "\n",
    "    # Separate data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    pID_train, pID_test = pID_arr[train_index], pID_arr[test_index]\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train, epochs=nb_epoch, verbose=0, validation_data=(X_test, y_test), shuffle=True)\n",
    "\n",
    "    #print model.summary()\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    #Save history\n",
    "    with open('results'+'.txt', 'wb') as file_pi:  \n",
    "        pickle.dump(model.history, file_pi)\n",
    "\n",
    "    # Make predictions\n",
    "    result = model.predict(X_test, verbose=2)\n",
    "\n",
    "    yfull_test.append(result)\n",
    "\n",
    "    # Store predictions\n",
    "    for i in range(len(test_index)):\n",
    "        yfull_train[test_index[i]] = result[i]\n",
    "\n",
    "    resultsFr = pd.DataFrame()\n",
    "    resultsFr['pID'] = pID_test\n",
    "    resultsFr['gt'] = y_test\n",
    "    resultsFr['nqloc'] = result\n",
    "    resultsFr['task'] = 1\n",
    "\n",
    "    results_full = results_full.append(resultsFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69acb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2dev",
   "language": "python",
   "name": "py2dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
